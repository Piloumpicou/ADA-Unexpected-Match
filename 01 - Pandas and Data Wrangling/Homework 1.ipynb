{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1\"><a href=\"#Task-1.-Compiling-Ebola-Data\"><span class=\"toc-item-num\">Task 1.&nbsp;&nbsp;</span>Compiling Ebola Data</a></div>\n",
    " <div class=\"lev1\"><a href=\"#Task-2.-RNA-Sequences\"><span class=\"toc-item-num\">Task 2.&nbsp;&nbsp;</span>RNA Sequences</a></div>\n",
    " <div class=\"lev1\"><a href=\"#Task-3.-Class-War-in-Titanic\"><span class=\"toc-item-num\">Task 3.&nbsp;&nbsp;</span>Class War in Titanic</a></div></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER = '../../ADA2017-Tutorials/02 - Intro to Pandas/Data/' # Use the data folder provided in Tutorial 02 - Intro to Pandas.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dateutil.parser import parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. Compiling Ebola Data\n",
    "\n",
    "The `DATA_FOLDER/ebola` folder contains summarized reports of Ebola cases from three countries (Guinea, Liberia and Sierra Leone) during the recent outbreak of the disease in West Africa. For each country, there are daily reports that contain various information about the outbreak in several cities in each country.\n",
    "\n",
    "Use pandas to import these data files into a single `Dataframe`.\n",
    "Using this `DataFrame`, calculate for *each country*, the *daily average per month* of *new cases* and *deaths*.\n",
    "Make sure you handle all the different expressions for *new cases* and *deaths* that are used in the reports."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On commence par analyser la stucture des fichiers : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date,Description,Totals,Conakry,Gueckedou,Macenta,Dabola,Kissidougou,Dinguiraye,Telimele,Boffa,Kouroussa,Siguiri,Pita,Mzerekore,Yomou,Dubreka,Forecariah,Kerouane,Coyah,Dalaba,Beyla,Kindia,Lola\n",
      "2014-09-11,New cases of suspects,9,,4,1,,,,,,,,,,,,1,3,,,,,\n",
      "\n",
      "\n",
      "Date,Variable,National,Bomi County,Bong County,Gbarpolu County,Grand Bassa,Grand Cape Mount,Grand Gedeh,Grand Kru,Lofa County,Margibi County,Maryland County,Montserrado County,Nimba County,River Gee County,RiverCess County,Sinoe County\n",
      "9/17/2014,Specimens collected,,,,,,,,,,,,,,,,\n",
      "\n",
      "\n",
      "date,variable,Kailahun,Kenema,Kono,Kambia,Koinadugu,Bombali,Tonkolili,Port Loko,Pujehun,Bo,Moyamba,Bonthe,Western area urban,Western area rural,National\n",
      "2014-08-18,population,\"465,048\",\"653,013\",\"325,003\",\"341,690\",\"335,471\",\"494,139\",\"434,937\",\"557,978\",\"335,574\",\"654,142\",\"278,119\",\"168,729\",\"1,040,888\",\"263,619\",\"6,348,350\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cat '../../ADA2017-Tutorials/02 - Intro to Pandas/Data/ebola/guinea_data/2014-09-11.csv' | head -n 2 \n",
    "! echo \"\\n\"\n",
    "!cat '../../ADA2017-Tutorials/02 - Intro to Pandas/Data/ebola/liberia_data/2014-09-17-v125.csv' | head -n 2\n",
    "! echo \"\\n\"\n",
    "!cat '../../ADA2017-Tutorials/02 - Intro to Pandas/Data/ebola/sl_data/2014-08-18-v83.csv' | head -n 2\n",
    "! echo \"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Premiere dificulter chaque pays à sont propre format mais Gloabalement similaire :\n",
    "Date , Description/Variable , Toatal/National , les donner pour chaque region ou county"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut voir ce que contien le champs variable/Description comme valeur avec la comande :\n",
    "\n",
    "`cat ../../ADA2017-Tutorials/02-\\ Intro\\ to\\ Pandas/Data/ebola/*/* |  cut -d, -f2  | sort | uniq`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Globalement on a des indication sur le nombre de mort et contaminer.\n",
    "On vois que beacoup de champs on des nom différent pour de meme indication comme par exepmle : new deaths registered et new deaths registered today.\n",
    "\n",
    "L'objectif etant d'avoir le nombre de nouveau cas et de mort par jour il faudra addisioner ces champs pour obetenir le nombre totale de nouveau cas ou de mort.\n",
    "\n",
    "On vas donc mettre le nombre de nouveau cas et de mort comme nom de colone pour avoir un tableau qui resemble a ça :\n",
    "\n",
    "Date,Pays,Regions, New case, death ...\n",
    "\n",
    "Ce qui sera plus facile pour obetenir des statistique par pays.\n",
    "\n",
    "Or nous avons vue les que donner sont dans un format \"transposer\" , il falloir donc transposer chaque fichier pour les mettre dans le format qui nous intérésse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3588, 144)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "data = pd.DataFrame() # creation d'une table vide\n",
    "\n",
    "# indique le nombre maximum de fichier a chargé : permet d'accéler le script pour debug\n",
    "max_file = 10000\n",
    "max_file_i = 0\n",
    "# pour chaque fichier de chaque répertoire\n",
    "for csv in  glob.glob(DATA_FOLDER+\"ebola/*/*.csv\"): \n",
    "    \n",
    "    # on lit le csv et on, rajoute - comme valeur manquante car - apparait parfois\n",
    "    subframe =  pd.read_csv(csv,na_values=\"-\")\n",
    "    \n",
    "    # on convertti tout les nom en minuscule pour avoir des nom normaliser\n",
    "    subframe.columns = [x.lower() for x in subframe.columns]\n",
    "    \n",
    "        \n",
    "    # on renome description pour avoir le meéne nom de colone pour chaques pays\n",
    "    if(subframe.columns[1]==\"description\") : \n",
    "        subframe.rename(columns={'description': 'variable'}, inplace=True)\n",
    "\n",
    "    # on récupére la date et on la convertit dans le formas de panda, la date unique dans chaque fichier\n",
    "    assert len(subframe['date'].drop_duplicates()) > 1\n",
    "    uniquedate = pd.to_datetime(subframe['date'][0])\n",
    "    # et on suprimme la colone date\n",
    "    subframe.drop('date',axis=1, inplace=True)\n",
    "    #on place en index les description des donner, lors de la traposer les description deviendron le nom des colone\n",
    "    subframe = subframe.set_index(\"variable\")\n",
    "    #on Transpose , ici maintenat on a un Data frame dont les donner sont les région et les colone les descriptions\n",
    "    subframe = subframe.transpose()\n",
    "    # on convertir tout les nouveau nom en minuscule pour ne pas avoir de probléme de comparaison\n",
    "    subframe.columns = [x.lower() for x in subframe.columns]\n",
    "    \n",
    "    # on s'assure que toute non donner soient biens intéerpere comme nomnbre\n",
    "    subframe = subframe.apply(pd.to_numeric,errors='ignore')\n",
    "    \n",
    "    #puis on rajoute la date\n",
    "    subframe['date'] = uniquedate\n",
    "\n",
    "    #et le pays\n",
    "    if \"guinea\" in csv :\n",
    "        subframe['country'] = \"Guinea\"\n",
    "    if \"liberia\" in csv :\n",
    "        subframe['country'] = \"Liberia\"\n",
    "    if \"sl\" in csv :\n",
    "        subframe['country'] = \"Siera Leon\"\n",
    "        \n",
    "    # lors de la transposer les nom des regtion sont de venue des index, on reset l'endex afin que les regtion devien un champs normale\n",
    "    subframe.reset_index(level=0, inplace=True)  \n",
    "    # et on attribut le nom regions au champs contenant les regions\n",
    "    subframe.rename(columns={'index': 'regions'}, inplace=True)\n",
    "\n",
    "    # on surpimme les colone qui sont dupliquer : la description pending est parfois en plusier exemplaire    \n",
    "    subframe = subframe.loc[:,~subframe.columns.duplicated()]\n",
    "\n",
    "    # ici on plance les donner date,country, et regions en premier \n",
    "    cols = ['date','country','regions']  + [col for col in subframe if (col != 'date' and col != 'country' and col != 'regions') ]\n",
    "    subframe = subframe[cols]\n",
    "    \n",
    "        \n",
    "    # puis on ajoute les donner au précédant DataFrame\n",
    "    if(len(data)==0):\n",
    "        data = subframe\n",
    "    else :\n",
    "  \n",
    "        data = pd.concat([data,subframe], axis=0, ignore_index=True)\n",
    "        # concat change l'odre des colone , on le remet dans l'odre de lecture\n",
    "        cols = ['date','country','regions']  + [col for col in data if (col != 'date' and col != 'country' and col != 'regions') ]\n",
    "        data = data[cols]\n",
    "       \n",
    "    # on stop si on a attent le nombre de fichier max\n",
    "    if(max_file_i>max_file):\n",
    "           break\n",
    "    max_file_i = max_file_i+1\n",
    "\n",
    "# il reste plus que a fussioner(addiosner) les colone qui on le méme sense  \n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant on rasemble le nombre de mort par jour et et nouveau contaminer.\n",
    "Ici on compte les cas suspec ,confirmer et probable.Mais c'est un choix arbitraire car l'enoncer ne présise pas quois faire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['total_new_death'] = data['new deaths registered'].fillna(0)+data['new deaths registered today'].fillna(0)+data['newly reported deaths'].fillna(0)+data['etc_new_deaths'].fillna(0)\n",
    "\n",
    "data['total_newcase'] = data[\"total new cases registered so far\"].fillna(0)+ data['new case/s (confirmed)'].fillna(0) + data['new case/s (probable)'].fillna(0) + data['new case/s (suspected)'].fillna(0) + data['new_confirmed'].fillna(0) + data['new_probable'].fillna(0) + data['new_suspected'].fillna(0); \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Puis on calcul la moyenne par pays et par mois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country     date      \n",
       "Guinea      2014-08-31      25.800000\n",
       "            2014-09-30      19.625000\n",
       "            2014-10-31      34.000000\n",
       "Liberia     2014-06-30       5.714286\n",
       "            2014-07-31       8.545455\n",
       "            2014-08-31      37.222222\n",
       "            2014-09-30      63.833333\n",
       "            2014-10-31      45.560000\n",
       "            2014-11-30      26.466667\n",
       "            2014-12-31    5178.555556\n",
       "Siera Leon  2014-08-31      25.150000\n",
       "            2014-09-30      40.689655\n",
       "            2014-10-31      70.928571\n",
       "            2014-11-30      75.238095\n",
       "            2014-12-31      41.000000\n",
       "Name: total_newcase, dtype: float64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_data = data[data['regions'].isin([\"national\" ,\"totals\"])].set_index(\"date\").groupby(['country',pd.TimeGrouper(freq='M')])\n",
    "gb_data['total_newcase'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country     date      \n",
       "Guinea      2014-08-31     3.400000\n",
       "            2014-09-30     3.562500\n",
       "            2014-10-31    15.000000\n",
       "Liberia     2014-06-30     2.000000\n",
       "            2014-07-31     4.272727\n",
       "            2014-08-31    23.222222\n",
       "            2014-09-30    36.041667\n",
       "            2014-10-31    28.040000\n",
       "            2014-11-30    13.466667\n",
       "            2014-12-31     0.000000\n",
       "Siera Leon  2014-08-31     0.000000\n",
       "            2014-09-30     0.275862\n",
       "            2014-10-31     3.535714\n",
       "            2014-11-30     0.571429\n",
       "            2014-12-31     2.200000\n",
       "Name: total_new_death, dtype: float64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_data['total_new_death'].mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. RNA Sequences\n",
    "\n",
    "In the `DATA_FOLDER/microbiome` subdirectory, there are 9 spreadsheets of microbiome data that was acquired from high-throughput RNA sequencing procedures, along with a 10<sup>th</sup> file that describes the content of each. \n",
    "\n",
    "Use pandas to import the first 9 spreadsheets into a single `DataFrame`.\n",
    "Then, add the metadata information from the 10<sup>th</sup> spreadsheet as columns in the combined `DataFrame`.\n",
    "Make sure that the final `DataFrame` has a unique index and all the `NaN` values have been replaced by the tag `unknown`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3. Class War in Titanic\n",
    "\n",
    "Use pandas to import the data file `Data/titanic.xls`. It contains data on all the passengers that travelled on the Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(filename=DATA_FOLDER+'/titanic.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the following questions state clearly your assumptions and discuss your findings:\n",
    "1. Describe the *type* and the *value range* of each attribute. Indicate and transform the attributes that can be `Categorical`. \n",
    "2. Plot histograms for the *travel class*, *embarkation port*, *sex* and *age* attributes. For the latter one, use *discrete decade intervals*. \n",
    "3. Calculate the proportion of passengers by *cabin floor*. Present your results in a *pie chart*.\n",
    "4. For each *travel class*, calculate the proportion of the passengers that survived. Present your results in *pie charts*.\n",
    "5. Calculate the proportion of the passengers that survived by *travel class* and *sex*. Present your results in *a single histogram*.\n",
    "6. Create 2 equally populated *age categories* and calculate survival proportions by *age category*, *travel class* and *sex*. Present your results in a `DataFrame` with unique index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
